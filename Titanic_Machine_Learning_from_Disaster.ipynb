{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iunzRUCM7FhE"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.13.11)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p d:\\ML-END_TO_END_PROJECT\\Titanic-Machine-Learning-from-Disaster\\venv ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7AQylw9ZMd"
      },
      "source": [
        "## Data Collection and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h68hffFu8Jw1"
      },
      "outputs": [],
      "source": [
        "Disaster_data=pd.read_csv('/content/Titanic - Machine Learning from Disaster.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Afg8A77m8Yar",
        "outputId": "c30ab05f-ba63-4086-cce8-2d77a4ef24da"
      },
      "outputs": [],
      "source": [
        "Disaster_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHk_nOm8d5G",
        "outputId": "bcd3d864-09c9-4598-ad75-0930e5b2b112"
      },
      "outputs": [],
      "source": [
        "Disaster_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "kd0qS9xN8h9B",
        "outputId": "1e396fdc-3b7e-4dc4-b95b-5795fddc0aec"
      },
      "outputs": [],
      "source": [
        "Disaster_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtee-xpv8vWS"
      },
      "outputs": [],
      "source": [
        "Disaster_data.drop(columns=['Cabin','Age','Embarked','Ticket'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Cj3rdzr787m9",
        "outputId": "799b3a2f-a083-447a-c14a-437a7fa3003c"
      },
      "outputs": [],
      "source": [
        "Disaster_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdU4Dst89hK6"
      },
      "source": [
        "# Separating the features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziPQI--x9V4d"
      },
      "outputs": [],
      "source": [
        "X=Disaster_data.drop(columns=['Survived', 'Name'],axis=1)\n",
        "Y=Disaster_data['Survived']\n",
        "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb1q8tgj9yvE",
        "outputId": "7428e697-e3bf-4bf0-c786-cdb93f58bf8d"
      },
      "outputs": [],
      "source": [
        "print(X)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg79rapZ94Ib"
      },
      "source": [
        "# Data Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSnr9eB793LP"
      },
      "outputs": [],
      "source": [
        "scaler=StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "IOAYoY-b_Fzl",
        "outputId": "78afb218-7a9b-4948-93dc-68666473c870"
      },
      "outputs": [],
      "source": [
        "scaler.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW-cqg-i-lQv",
        "outputId": "1850cd6e-8245-4724-f705-1e047e64c64a"
      },
      "outputs": [],
      "source": [
        "scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "lxXbmN0r_s3o",
        "outputId": "4b4ed085-edec-4f8a-a50c-ce27395da020"
      },
      "outputs": [],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgZXUVZK_0sa"
      },
      "source": [
        "# Splitting data into Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFRxxvfj_zEu"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSbzBUxlAOpX",
        "outputId": "f5e0d037-c67d-4612-e52c-12be7f41d64d"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9XAMPVQAVvg"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "f9xaM7RYAUhJ",
        "outputId": "f7082f7d-b0a5-4ec5-be8c-96e2b222bc29"
      },
      "outputs": [],
      "source": [
        "model=SVC()\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbpPjIaNA45j"
      },
      "source": [
        "## Accuracy on Traning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM-2WG08A1h8"
      },
      "outputs": [],
      "source": [
        "x_train_pred=model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Xoa88DBFkx",
        "outputId": "b7ed36d8-0412-436f-e5cf-73e7996574bd"
      },
      "outputs": [],
      "source": [
        "x_train_Accuracy=accuracy_score(x_train_pred, y_train)\n",
        "print(x_train_Accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa0bb993"
      },
      "source": [
        "# Task\n",
        "Apply StandardScaler and split the *scaled* data into training and testing sets, then calculate and print the accuracy of the currently trained SVC model on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf71a449"
      },
      "source": [
        "## Apply StandardScaler and Split Data\n",
        "\n",
        "### Subtask:\n",
        "Apply the initialized StandardScaler to your features (X) and then split the *scaled* data into training and testing sets. This ensures your model is trained and evaluated on properly scaled data, which is crucial for SVM performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2effbb6"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires applying the initialized StandardScaler to the feature DataFrame `X` and then splitting the *scaled* data along with the target variable `Y` into training and testing sets. This step will first transform `X` to `X_scaled` and then perform the train-test split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c1beb77"
      },
      "outputs": [],
      "source": [
        "X_scaled = scaler.transform(X)\n",
        "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077dd167"
      },
      "source": [
        "**Reasoning**:\n",
        "To complete the subtask of calculating the accuracy on the test dataset using the currently trained SVC model, predictions need to be made on the `x_test_scaled` data, and then the accuracy score needs to be calculated by comparing these predictions to `y_test`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e587d2da",
        "outputId": "0d3d57cf-ce10-472a-9149-1f4c8fdf33cf"
      },
      "outputs": [],
      "source": [
        "y_pred_scaled = model.predict(x_test_scaled)\n",
        "test_accuracy_scaled = accuracy_score(y_pred_scaled, y_test)\n",
        "print(f\"Accuracy of the currently trained model on the scaled test data: {test_accuracy_scaled}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2e1630d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous warning indicated an inconsistency where the SVC model was fitted on data with feature names (unscaled DataFrame) but was asked to predict on data without (scaled NumPy array). To ensure proper model training and evaluation with scaled data, the model needs to be re-trained on the `x_train_scaled` dataset. This step will re-initialize the SVC model, train it on the scaled training data, and then calculate its accuracy on the scaled test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a4d0304",
        "outputId": "7f26dbae-9f6b-4cde-cdda-d522468a3ae9"
      },
      "outputs": [],
      "source": [
        "model=SVC()\n",
        "model.fit(x_train_scaled, y_train)\n",
        "\n",
        "y_pred_scaled = model.predict(x_test_scaled)\n",
        "test_accuracy_scaled = accuracy_score(y_pred_scaled, y_test)\n",
        "print(f\"Accuracy of the retrained model on the scaled test data: {test_accuracy_scaled}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10d6021d"
      },
      "source": [
        "## Hyperparameter Tuning for SVC\n",
        "\n",
        "### Subtask:\n",
        "Improve the SVC model's performance by systematically searching for the best hyperparameters (e.g., 'C', 'kernel', 'gamma') using techniques like GridSearchCV or RandomizedSearchCV. This can significantly impact accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3535cfa8"
      },
      "source": [
        "**Reasoning**:\n",
        "To improve the SVC model's performance, I will perform hyperparameter tuning using `GridSearchCV`. This involves importing `GridSearchCV`, defining a parameter grid, initializing an SVC model, instantiating `GridSearchCV`, fitting it to the scaled training data, and then printing the best parameters and best cross-validation score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20888cc",
        "outputId": "babd41f6-2d42-481c-b571-751a443dc831"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Initialize an SVC model\n",
        "svc_model = SVC(random_state=2)\n",
        "\n",
        "# Instantiate GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=svc_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the scaled training data\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and best cross-validation score\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6925aa"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the best hyperparameters have been identified, the next step is to evaluate the model's performance on the scaled test data using these optimal parameters. This involves retrieving the best estimator from the `GridSearchCV` object, making predictions on the `x_test_scaled` data, and then calculating and printing the accuracy score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a35dc0",
        "outputId": "4eb1f117-2dbf-425a-b9e6-8f03757b7c62"
      },
      "outputs": [],
      "source": [
        "best_svc_model = grid_search.best_estimator_\n",
        "y_pred_best = best_svc_model.predict(x_test_scaled)\n",
        "test_accuracy_best = accuracy_score(y_pred_best, y_test)\n",
        "print(f\"Accuracy of the SVC model with best hyperparameters on the scaled test data: {test_accuracy_best}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1bc0d95",
        "outputId": "258cd8bf-c475-48b9-841b-2ddcb727044e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the best SVC model to a file\n",
        "filename = 'best_svc_model.pkl'\n",
        "pickle.dump(best_svc_model, open(filename, 'wb'))\n",
        "pickled_model=pickle.load(open(filename,'rb'))\n",
        "\n",
        "print(pickled_model.predict(x_test_scaled[0].reshape(1,-1)))\n",
        "print(f\"Best SVC model saved to {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c03e3399"
      },
      "source": [
        "## Evaluate Tuned Model\n",
        "\n",
        "### Subtask:\n",
        "Train the SVC model with the optimal hyperparameters found during tuning and evaluate its accuracy on both the training and test sets to see the improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73296a0c"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the performance of the `best_svc_model` on the training data, I will make predictions on the scaled training features and calculate the accuracy against the actual training labels. Then, I will print both the training and previously calculated test accuracies for comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8cefc4",
        "outputId": "d10cffc2-ceef-401b-bb93-04ed4ba36d21"
      },
      "outputs": [],
      "source": [
        "y_train_pred_best = best_svc_model.predict(x_train_scaled)\n",
        "train_accuracy_best = accuracy_score(y_train_pred_best, y_train)\n",
        "print(f\"Training accuracy of the SVC model with best hyperparameters: {train_accuracy_best}\")\n",
        "print(f\"Test accuracy of the SVC model with best hyperparameters: {test_accuracy_best}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d680ef4b"
      },
      "source": [
        "## Explore Other Models\n",
        "\n",
        "### Subtask:\n",
        "Explore other classification algorithms like Logistic Regression, RandomForestClassifier, or GradientBoostingClassifier. These models might capture different patterns in the data and yield better results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52c669a"
      },
      "source": [
        "**Reasoning**:\n",
        "To explore other classification algorithms as requested, I will import `LogisticRegression`, `RandomForestClassifier`, and `GradientBoostingClassifier`, initialize them with specified parameters, train them on the scaled training data, make predictions on the scaled test data, and then calculate and print the accuracy score for each model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c85c2222",
        "outputId": "003b042c-9b0f-4dbf-ffd5-4ba5bcbfc147"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Initialize models\n",
        "logistic_model = LogisticRegression(solver='liblinear', random_state=2)\n",
        "random_forest_model = RandomForestClassifier(random_state=2)\n",
        "gradient_boosting_model = GradientBoostingClassifier(random_state=2)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "logistic_model.fit(x_train_scaled, y_train)\n",
        "# Make predictions and calculate accuracy for Logistic Regression\n",
        "y_pred_logistic = logistic_model.predict(x_test_scaled)\n",
        "accuracy_logistic = accuracy_score(y_pred_logistic, y_test)\n",
        "print(f\"Logistic Regression Accuracy on scaled test data: {accuracy_logistic}\")\n",
        "\n",
        "# Train Random Forest Classifier model\n",
        "random_forest_model.fit(x_train_scaled, y_train)\n",
        "# Make predictions and calculate accuracy for Random Forest Classifier\n",
        "y_pred_rf = random_forest_model.predict(x_test_scaled)\n",
        "accuracy_rf = accuracy_score(y_pred_rf, y_test)\n",
        "print(f\"Random Forest Classifier Accuracy on scaled test data: {accuracy_rf}\")\n",
        "\n",
        "# Train Gradient Boosting Classifier model\n",
        "gradient_boosting_model.fit(x_train_scaled, y_train)\n",
        "# Make predictions and calculate accuracy for Gradient Boosting Classifier\n",
        "y_pred_gb = gradient_boosting_model.predict(x_test_scaled)\n",
        "accuracy_gb = accuracy_score(y_pred_gb, y_test)\n",
        "print(f\"Gradient Boosting Classifier Accuracy on scaled test data: {accuracy_gb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143c20c8"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the improvements in accuracy and discuss further steps based on the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ec0a47"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**1. What are the improvements in accuracy after applying different modeling techniques?**\n",
        "*   Initially, an existing SVC model (likely trained on unscaled data) achieved an accuracy of 0.5587 on scaled test data.\n",
        "*   After retraining the SVC model on properly scaled training data, the accuracy significantly improved to 0.7709.\n",
        "*   Hyperparameter tuning of the SVC model using `GridSearchCV` resulted in a test accuracy of 0.7709, with a training accuracy of 0.8202 and a best cross-validation accuracy of 0.8104.\n",
        "*   Other classification models yielded the following test accuracies:\n",
        "    *   Logistic Regression: 0.7654\n",
        "    *   Random Forest Classifier: 0.7654\n",
        "    *   Gradient Boosting Classifier: 0.7598\n",
        "\n",
        "**2. What further steps should be taken based on the results?**\n",
        "*   Consider implementing advanced ensemble techniques or exploring more complex neural network architectures if further performance gains are needed.\n",
        "*   Investigate the model's errors (e.g., false positives, false negatives) to understand specific areas of weakness and guide further feature engineering or data collection efforts.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Scaling the data and retraining the Support Vector Classifier (SVC) model dramatically improved its test accuracy from 0.5587 to 0.7709.\n",
        "*   Hyperparameter tuning of the SVC model using `GridSearchCV` identified `{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}` as the optimal parameters, achieving a best cross-validation accuracy of approximately 0.8104.\n",
        "*   The tuned SVC model showed a training accuracy of 0.8202 and a test accuracy of 0.7709, indicating good generalization, although there's a slight gap between training and test performance.\n",
        "*   When exploring other models:\n",
        "    *   Logistic Regression achieved a test accuracy of 0.7654.\n",
        "    *   Random Forest Classifier achieved a test accuracy of 0.7654.\n",
        "    *   Gradient Boosting Classifier achieved a test accuracy of 0.7598.\n",
        "*   The tuned SVC model performed comparably to, or slightly better than, the other explored classification algorithms on the scaled test data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The proper scaling of features and subsequent retraining of the model are crucial steps for optimal performance with algorithms like SVC.\n",
        "*   While the tuned SVC model performed well, fine-tuning the hyperparameters for the other models (Logistic Regression, Random Forest, Gradient Boosting) could potentially lead to marginal improvements and should be considered for a more exhaustive comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1xvbEQeKnxp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
